{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "# AI Service Deployment Notebook\n",
    "This notebook contains steps and code to test, promote, and deploy an Agent as an AI Service.\n",
    "\n",
    "**Note:** Notebook code generated using Agent Lab will execute successfully.\n",
    "If code is modified or reordered, there is no guarantee it will successfully execute.\n",
    "For details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n",
    "\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
    "\n",
    "## Contents\n",
    "This notebook contains the following parts:\n",
    "\n",
    "1. Setup\n",
    "2. Initialize all the variables needed by the AI Service\n",
    "3. Define the AI service function\n",
    "4. Deploy an AI Service\n",
    "5. Test the deployed AI Service\n",
    "\n",
    "## 1. Set up the environment\n",
    "\n",
    "Before you can run this notebook, you must perform the following setup tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection to WML\n",
    "This cell defines the credentials required to work with watsonx API for both the execution in the project, \n",
    "as well as the deployment and runtime execution of the function.\n",
    "\n",
    "**Action:** Provide the IBM Cloud personal API key. For details, see\n",
    "<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ibm_watsonx_ai import APIClient, Credentials\n",
    "import getpass\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key=getpass.getpass(\"Please enter your api key (hit enter): \")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting IAM Token.\n",
      "Reason: <Response [400]>\n"
     ]
    },
    {
     "ename": "WMLClientError",
     "evalue": "Error getting IAM Token.\nReason: <Response [400]>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mWMLClientError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m client = \u001b[43mAPIClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pujit\\OneDrive\\Desktop\\data2\\.venv\\Lib\\site-packages\\ibm_watsonx_ai\\client.py:489\u001b[39m, in \u001b[36mAPIClient.__init__\u001b[39m\u001b[34m(self, credentials, project_id, space_id, verify, httpx_client, async_httpx_client, **kwargs)\u001b[39m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._href_definitions = _create_href_definitions(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    488\u001b[39m \u001b[38;5;28mself\u001b[39m._auth_method = get_auth_method(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auth_method\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# For cloud, service_instance.details will be set during space creation( if instance is associated ) or\u001b[39;00m\n\u001b[32m    492\u001b[39m \u001b[38;5;66;03m# while patching a space with an instance\u001b[39;00m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m.service_instance: ServiceInstance = ServiceInstance(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pujit\\OneDrive\\Desktop\\data2\\.venv\\Lib\\site-packages\\ibm_watsonx_ai\\utils\\auth\\base_auth.py:100\u001b[39m, in \u001b[36mRefreshableTokenAuth.get_token\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m         \u001b[38;5;28mself\u001b[39m._save_token_data(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    101\u001b[39m         \u001b[38;5;28mself\u001b[39m._set_refreshing_timedelta_if_needed()\n\u001b[32m    103\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._on_token_creation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pujit\\OneDrive\\Desktop\\data2\\.venv\\Lib\\site-packages\\ibm_watsonx_ai\\utils\\auth\\iam_auth.py:72\u001b[39m, in \u001b[36mIAMTokenAuth._generate_token\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m TokenInfo(response.json().get(\u001b[33m\"\u001b[39m\u001b[33maccess_token\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\u001b[33m\"\u001b[39m\u001b[33mError getting IAM Token.\u001b[39m\u001b[33m\"\u001b[39m, response)\n",
      "\u001b[31mWMLClientError\u001b[39m: Error getting IAM Token.\nReason: <Response [400]>"
     ]
    }
   ],
   "source": [
    "client = APIClient(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to a space\n",
    "A space will be be used to host the promoted AI Service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_id = \"486d60ab-bb07-48fd-b3cd-839f25feaef1\"\n",
    "client.set.default_space(space_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promote asset(s) to space\n",
    "We will now promote assets we will need to stage in the space so that we can access their data from the AI service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_project_id = \"c847d923-bb0d-4a3c-a4d4-da7612e674be\"\n",
    "vector_index_id = client.spaces.promote(\"9a469e49-205d-4f57-a251-69e4f41112b8\", source_project_id, space_id)\n",
    "print(vector_index_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create the AI service function\n",
    "We first need to define the AI service function\n",
    "\n",
    "### 2.1 Define the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"space_id\": space_id,\n",
    "    \"vector_index_id\": vector_index_id\n",
    "}\n",
    "\n",
    "def gen_ai_service(context, params = params, **custom):\n",
    "    # import dependencies\n",
    "    from langchain_ibm import ChatWatsonx\n",
    "    from ibm_watsonx_ai import APIClient\n",
    "    from ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\n",
    "    from langchain_core.messages import AIMessage, HumanMessage\n",
    "    from langgraph.checkpoint.memory import MemorySaver\n",
    "    from langgraph.prebuilt import create_react_agent\n",
    "    import json\n",
    "    import requests\n",
    "\n",
    "    model = \"meta-llama/llama-3-3-70b-instruct\"\n",
    "    \n",
    "    service_url = \"https://us-south.ml.cloud.ibm.com\"\n",
    "    # Get credentials token\n",
    "    credentials = {\n",
    "        \"url\": service_url,\n",
    "        \"token\": context.generate_token()\n",
    "    }\n",
    "\n",
    "    # Setup client\n",
    "    client = APIClient(credentials)\n",
    "    space_id = params.get(\"space_id\")\n",
    "    client.set.default_space(space_id)\n",
    "\n",
    "\n",
    "    def decrypt_tool_secrets(secrets):\n",
    "        url = \"https://api.dataplatform.cloud.ibm.com\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f'Bearer {context.generate_token()}'\n",
    "        }\n",
    "    \n",
    "        body = {\n",
    "            \"secrets\": secrets,\n",
    "            \"space_id\": space_id\n",
    "        }\n",
    "    \n",
    "        response = requests.post(f'{url}/wx/v1-beta/utility_agent_tools/secret/decrypt', headers=headers, json=body)\n",
    "    \n",
    "        return response.json().get(\"secrets\")\n",
    "    \n",
    "    encrypted_secrets = [\n",
    "        \"gcm-agent-tools-qHi31me0EfjVZVuGAnau05GBdpyvCVyV:mZxy1kjznH8ajwW1i7ypOg==;X2+QjKnh8yP+60Dc9g3xMw==:s14D2Hb9eZ3EaCMqAjH5y8Dl0nOxmM9AC4I+jgEeaHwN1jlFZ9NMOQE=\"\n",
    "    ]\n",
    "    decrypted_secrets = decrypt_tool_secrets(encrypted_secrets)\n",
    "    \n",
    "    TavilySearch_apiKey = decrypted_secrets[0]\n",
    "    \n",
    "    vector_index_id = params.get(\"vector_index_id\")\n",
    "\n",
    "    def create_rag_tool(vector_index_id, api_client):\n",
    "        config = {\n",
    "            \"vectorIndexId\": vector_index_id,\n",
    "            \"spaceId\": space_id\n",
    "        }\n",
    "    \n",
    "        tool_description = \"Search information in documents to provide context to a user query. Useful when asked to ground the answer in specific knowledge about Department Data\"\n",
    "        \n",
    "        return create_utility_agent_tool(\"RAGQuery\", config, api_client, tool_description=tool_description)\n",
    "    \n",
    "\n",
    "    def create_chat_model(watsonx_client):\n",
    "        parameters = {\n",
    "            \"frequency_penalty\": 0,\n",
    "            \"max_tokens\": 2000,\n",
    "            \"presence_penalty\": 0,\n",
    "            \"temperature\": 0,\n",
    "            \"top_p\": 1\n",
    "        }\n",
    "\n",
    "        chat_model = ChatWatsonx(\n",
    "            model_id=model,\n",
    "            url=service_url,\n",
    "            space_id=space_id,\n",
    "            params=parameters,\n",
    "            watsonx_client=watsonx_client,\n",
    "        )\n",
    "        return chat_model\n",
    "    \n",
    "    def create_python_interpreter_tool(context):\n",
    "        from langchain_core.tools import StructuredTool\n",
    "    \n",
    "        import ast\n",
    "        import sys\n",
    "        from io import StringIO\n",
    "        import uuid\n",
    "        import base64\n",
    "        import os\n",
    "    \n",
    "        original_import = __import__\n",
    "        \n",
    "        def get_image_url(base_64_content, image_name, context):\n",
    "            url = \"https://api.dataplatform.cloud.ibm.com\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f'Bearer {context.get_token()}'\n",
    "            }\n",
    "    \n",
    "            body = {\n",
    "                \"name\": image_name,\n",
    "                \"blob\": base_64_content\n",
    "            }\n",
    "    \n",
    "            params = {\n",
    "                \"space_id\": space_id\n",
    "            }\n",
    "    \n",
    "            response = requests.post(f'{url}/wx/v1-beta/utility_agent_tools/resources', headers=headers, json=body, params=params)\n",
    "    \n",
    "            return response.json().get(\"uri\")\n",
    "    \n",
    "        def patched_import(name, globals=None, locals=None, fromlist=(), level=0):\n",
    "            module = original_import(name, globals, locals, fromlist, level)\n",
    "        \n",
    "            if name == \"matplotlib.pyplot\":\n",
    "                sys.modules[\"matplotlib.pyplot\"].show = pyplot_show\n",
    "            return module\n",
    "        \n",
    "        def pyplot_show():\n",
    "            pictureName = \"plt-\" + uuid.uuid4().hex + \".png\"\n",
    "            plt = sys.modules[\"matplotlib.pyplot\"]\n",
    "            plt.savefig(pictureName)\n",
    "            with open(pictureName, \"rb\") as image_file:\n",
    "                encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "                print(f\"base64image:{pictureName}:{str(encoded_string)}\")\n",
    "                os.remove(pictureName)\n",
    "                plt.clf()\n",
    "                plt.close(\"all\")\n",
    "        \n",
    "        def init_imports():\n",
    "            import builtins\n",
    "            builtins.__import__ = patched_import\n",
    "        \n",
    "        def _executeAgentCode(code):\n",
    "            old_stdout = sys.stdout\n",
    "            try:\n",
    "                full_code = \"init_imports()\\n\\n\" + code\n",
    "                tree = ast.parse(full_code, mode=\"exec\")\n",
    "                compiled_code = compile(tree, 'agent_code', 'exec')\n",
    "                namespace = {\"init_imports\": init_imports}\n",
    "                redirected_output = sys.stdout = StringIO(\"\")\n",
    "                exec(compiled_code, namespace)\n",
    "                value = redirected_output.getvalue()\n",
    "                if (value.startswith(\"base64image\")):\n",
    "                    image_details = value.split(\":\")\n",
    "                    image_name = image_details[1]\n",
    "                    base_64_image = image_details[2]\n",
    "                    image_url = get_image_url(base_64_image, image_name, context)\n",
    "                    value = f\"Result of executing generated Python code is an image:\\n\\nIMAGE({image_url})\"\n",
    "            except Exception as e:\n",
    "                value = \"Error while executing Python code:\\n\\n\" + str(e)\n",
    "            finally:\n",
    "                sys.stdout = old_stdout\n",
    "            return value\n",
    "    \n",
    "        tool_description = \"\"\"Run Python code and return the console output. Use for isolated calculations, computations or data manipulation. In Python, the following modules are available: Use numpy, pandas, scipy and sympy for working with data. Use matplotlib to plot charts. Other Python libraries are also available -- however, prefer using the ones above. Prefer using qualified imports -- `import library; library.thing()` instead of `import thing from library`. Do not attempt to install libraries manually -- it will not work. Do not use this tool multiple times in a row, always write the full code you want to run in a single invocation. If you get an error running Python code, try to generate a better one that will pass. If the tool returns result that starts with IMAGE(, follow instructions for rendering images.\"\"\"\n",
    "        tool_schema = {\n",
    "            \"type\": \"object\",\n",
    "            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "            \"properties\": {\n",
    "                \"code\": {\n",
    "                    \"description\": \"Code to be executed.\",\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"code\"]\n",
    "        }\n",
    "        \n",
    "        return StructuredTool(\n",
    "            name=\"PythonInterpreter\",\n",
    "            description = tool_description,\n",
    "            func=_executeAgentCode,\n",
    "            args_schema=tool_schema\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n",
    "        from langchain_core.tools import StructuredTool\n",
    "        utility_agent_tool = Toolkit(\n",
    "            api_client=api_client\n",
    "        ).get_tool(tool_name)\n",
    "    \n",
    "        tool_description = utility_agent_tool.get(\"description\")\n",
    "    \n",
    "        if (kwargs.get(\"tool_description\")):\n",
    "            tool_description = kwargs.get(\"tool_description\")\n",
    "        elif (utility_agent_tool.get(\"agent_description\")):\n",
    "            tool_description = utility_agent_tool.get(\"agent_description\")\n",
    "        \n",
    "        tool_schema = utility_agent_tool.get(\"input_schema\")\n",
    "        if (tool_schema == None):\n",
    "            tool_schema = {\n",
    "                \"type\": \"object\",\n",
    "                \"additionalProperties\": False,\n",
    "                \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "                \"properties\": {\n",
    "                    \"input\": {\n",
    "                        \"description\": \"input for the tool\",\n",
    "                        \"type\": \"string\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        def run_tool(**tool_input):\n",
    "            query = tool_input\n",
    "            if (utility_agent_tool.get(\"input_schema\") == None):\n",
    "                query = tool_input.get(\"input\")\n",
    "    \n",
    "            results = utility_agent_tool.run(\n",
    "                input=query,\n",
    "                config=params\n",
    "            )\n",
    "            \n",
    "            return results.get(\"output\")\n",
    "        \n",
    "        return StructuredTool(\n",
    "            name=tool_name,\n",
    "            description = tool_description,\n",
    "            func=run_tool,\n",
    "            args_schema=tool_schema\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n",
    "        from langchain_core.tools import StructuredTool\n",
    "        import ast\n",
    "    \n",
    "        def call_tool(**kwargs):\n",
    "            tree = ast.parse(tool_code, mode=\"exec\")\n",
    "            custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n",
    "            function_name = custom_tool_functions[0].name\n",
    "            compiled_code = compile(tree, 'custom_tool', 'exec')\n",
    "            namespace = tool_params if tool_params else {}\n",
    "            exec(compiled_code, namespace)\n",
    "            return namespace[function_name](**kwargs)\n",
    "            \n",
    "        tool = StructuredTool(\n",
    "            name=tool_name,\n",
    "            description = tool_description,\n",
    "            func=call_tool,\n",
    "            args_schema=tool_schema\n",
    "        )\n",
    "        return tool\n",
    "    \n",
    "    def create_custom_tools():\n",
    "        custom_tools = []\n",
    "    \n",
    "        name_WellnessTrendAnalyzerTool_3uyo5 = \"WellnessTrendAnalyzerTool\"\n",
    "        desc_WellnessTrendAnalyzerTool_3uyo5 = \"\"\"Analyzes the anonymized corporate wellness data file to report on high-level trends. Use this tool to answer questions about popular interests, challenge engagement, or mood trends across different segments of the company like departments or work types.\"\"\"\n",
    "        code_WellnessTrendAnalyzerTool_3uyo5 = \"\"\"# Required imports for reading data assets\\nimport pandas as pd\\nimport json\\nimport io\\nfrom ibm_watson_studio_lib import access_project_or_space\\n\\ndef analyze_wellness_trends(metric: str, filter_criteria: str = None) -> str:\\n    \"\"\"\\n    Analyzes the anonymized corporate wellness data from a project asset to report on high-level trends.\\n\\n    Args:\\n        metric (str): The specific metric to analyze. Supported values: \\n                      'popular_interests', 'challenge_completion', 'mood_trends'.\\n        filter_criteria (str): A JSON string dictionary to filter the data. \\n                               Example: '{\"department\": \"Engineering\"}' or '{\"workType\": \"Remote\"}'.\\n\\n    Returns:\\n        str: A string containing the formatted analysis report.\\n    \"\"\"\\n    # --- Step 1: Load the data from the Watsonx Project Asset ---\\n    try:\\n        # Initialize the library to access project assets\\n        wslib = access_project_or_space()\\n        \\n        # The name of the data asset you uploaded\\n        data_asset_name = 'synthetic_hr_wellness_data.csv'\\n        \\n        # Load the asset's content into memory as bytes\\n        csv_bytes = wslib.load_data(data_asset_name)\\n        \\n        # Use pandas to read the bytes data. io.BytesIO treats the bytes as a file.\\n        df = pd.read_csv(io.BytesIO(csv_bytes))\\n        \\n    except Exception as e:\\n        return f\"Error: Failed to load or process the data asset '{data_asset_name}'. Details: {e}\"\\n\\n    # --- Step 2: The rest of your analysis logic (this part remains the same) ---\\n    \\n    # Apply filters if provided\\n    title = \"Analysis Report for the Entire Company\"\\n    if filter_criteria and filter_criteria.lower() not in ['null', '']:\\n        try:\\n            filters = json.loads(filter_criteria)\\n            filter_desc = []\\n            for column, value in filters.items():\\n                if column in df.columns:\\n                    df = df[df[column] == value]\\n                    filter_desc.append(f\"{column} = '{value}'\")\\n                else:\\n                    return f\"Error: Invalid filter column '{column}'. Please use a valid column name.\"\\n            if not df.empty:\\n                title = f\"Analysis Report for employees where {', '.join(filter_desc)}\"\\n            else:\\n                return f\"No data found for the specified filter: {filter_criteria}\"\\n        except json.JSONDecodeError:\\n            return \"Error: Invalid format for filter_criteria. It must be a valid JSON string like '{\\\"column\\\": \\\"value\\\"}'.\"\\n        except Exception as e:\\n            return f\"An unexpected error occurred during filtering: {e}\"\\n\\n\\n    # --- Metric Calculation ---\\n    report = f\"--- {title} ---\\n\\n\"\\n\\n    if metric == 'popular_interests':\\n        interests = df['wellnessInterests'].str.split(';').explode()\\n        top_interests = interests.value_counts().nlargest(5)\\n        report += \"Top 5 Most Popular Wellness Interests:\\n\"\\n        if top_interests.empty:\\n            report += \"No interest data available for this segment.\\n\"\\n        else:\\n            for i, (interest, count) in enumerate(top_interests.items()):\\n                report += f\"{i+1}. {interest} ({count} employees)\\n\"\\n\\n    elif metric == 'challenge_completion':\\n        completion_stats = df['lastChallengeCompletionStatus'].value_counts(normalize=True).mul(100).round(1)\\n        report += \"Challenge Completion Rate:\\n\"\\n        if completion_stats.empty:\\n            report += \"No challenge data available for this segment.\\n\"\\n        else:\\n            for status, percentage in completion_stats.items():\\n                report += f\"- {status}: {percentage}%\\n\"\\n\\n    elif metric == 'mood_trends':\\n        mood_stats = df['selfReportedMood'].value_counts()\\n        report += \"Self-Reported Mood Distribution:\\n\"\\n        if mood_stats.empty:\\n            report += \"No mood data available for this segment.\\n\"\\n        else:\\n            for mood, count in mood_stats.items():\\n                report += f\"- {mood}: {count} employees\\n\"\\n    \\n    else:\\n        return f\"Error: Invalid metric '{metric}'. Please use one of: 'popular_interests', 'challenge_completion', 'mood_trends'.\"\\n\\n    report += f\"\\nTotal employees in this segment: {len(df)}\"\\n    return report\"\"\"\n",
    "        params_WellnessTrendAnalyzerTool_3uyo5 = {\n",
    "        }\n",
    "    \n",
    "        schema_WellnessTrendAnalyzerTool_3uyo5 = {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"metric\": {\n",
    "                    \"title\": \"Metric\",\n",
    "                    \"description\": \"Must be one of: popular_interests | challenge_completion | mood_trends.\",\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"popular_interests\",\"challenge_completion\",\"mood_trends\"],\n",
    "                    \"minLength\": 1\n",
    "                },\n",
    "                \"filter_criteria\": {\n",
    "                    \"title\": \"Filter criteria\",\n",
    "                    \"description\": \"JSON string like {\\\"department\\\": \\\"Engineering\\\"}. Leave empty or 'null' for no filter.\",\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        custom_tools.append(create_custom_tool(name_WellnessTrendAnalyzerTool_3uyo5, desc_WellnessTrendAnalyzerTool_3uyo5, code_WellnessTrendAnalyzerTool_3uyo5, schema_WellnessTrendAnalyzerTool_3uyo5, params_WellnessTrendAnalyzerTool_3uyo5))\n",
    "    \n",
    "        return custom_tools\n",
    "    \n",
    "\n",
    "    def create_tools(inner_client, context):\n",
    "        tools = []\n",
    "        tools.append(create_rag_tool(vector_index_id, inner_client))\n",
    "        tools.append(create_python_interpreter_tool(context))\n",
    "        \n",
    "        config = None\n",
    "        tools.append(create_utility_agent_tool(\"GoogleSearch\", config, inner_client))\n",
    "        config = {\n",
    "            \"maxResults\": 10,\n",
    "            \"apiKey\": TavilySearch_apiKey\n",
    "        }\n",
    "        tools.append(create_utility_agent_tool(\"TavilySearch\", config, inner_client))\n",
    "        config = {\n",
    "        }\n",
    "        tools.append(create_utility_agent_tool(\"DuckDuckGo\", config, inner_client))\n",
    "        config = {\n",
    "        }\n",
    "        tools.append(create_utility_agent_tool(\"Weather\", config, inner_client))\n",
    "        tools = tools + create_custom_tools()\n",
    "        return tools\n",
    "    \n",
    "    def create_agent(model, tools, messages):\n",
    "        memory = MemorySaver()\n",
    "        instructions = \"\"\"# Notes\n",
    "- Use markdown syntax for formatting code snippets, links, JSON, tables, images, files.\n",
    "- Any HTML tags must be wrapped in block quotes, for example ```<html>```.\n",
    "- When returning code blocks, specify language.\n",
    "- Sometimes, things don't go as planned. Tools may not provide useful information on the first few tries. You should always try a few different approaches before declaring the problem unsolvable.\n",
    "- When the tool doesn't give you what you were asking for, you must either use another tool or a different tool input.\n",
    "- When using search engines, you try different formulations of the query, possibly even in a different language.\n",
    "- You cannot do complex calculations, computations, or data manipulations without using tools.\n",
    "- If you need to call a tool to compute something, always call it instead of saying you will call it.\n",
    "\n",
    "If a tool returns an IMAGE in the result, you must include it in your answer as Markdown.\n",
    "\n",
    "Example:\n",
    "\n",
    "Tool result: IMAGE({commonApiUrl}/wx/v1-beta/utility_agent_tools/cache/images/plt-04e3c91ae04b47f8934a4e6b7d1fdc2c.png)\n",
    "Markdown to return to user: ![Generated image]({commonApiUrl}/wx/v1-beta/utility_agent_tools/cache/images/plt-04e3c91ae04b47f8934a4e6b7d1fdc2c.png)\n",
    "\n",
    "You are the AltWellTab Agent, a friendly and professional corporate wellness assistant.\n",
    "\n",
    "Your role:\n",
    "- Always introduce yourself as the AltWellTab Agent when starting a conversation.\n",
    "- Explain that you can generate fun and engaging corporate wellness challenges aligned with the company’s schedule.\n",
    "- Use HR data from the knowledge base to personalize challenges, track participation, and analyze performance trends.\n",
    "- Provide clear, actionable performance analysis and suggest improvements.\n",
    "- Offer additional wellness insights such as nutrition tips, micro-break reminders, and stress-relief exercises when appropriate.\n",
    "- Maintain a supportive, motivational, and approachable tone at all times.\n",
    "\n",
    "Example introduction:\n",
    "“Hi! I’m the AltWellTab Agent 👋. I can help you create fun corporate wellness challenges tailored to your team’s schedule. I also analyze participation and performance data to give helpful suggestions for improvement. Plus, I can share wellness tips, reminders, and much more to keep your workplace healthier and more energized!”\n",
    "\"\"\"\n",
    "        for message in messages:\n",
    "            if message[\"role\"] == \"system\":\n",
    "                instructions += message[\"content\"]\n",
    "        graph = create_react_agent(model, tools=tools, checkpointer=memory, state_modifier=instructions)\n",
    "        return graph\n",
    "    \n",
    "    def convert_messages(messages):\n",
    "        converted_messages = []\n",
    "        for message in messages:\n",
    "            if (message[\"role\"] == \"user\"):\n",
    "                converted_messages.append(HumanMessage(content=message[\"content\"]))\n",
    "            elif (message[\"role\"] == \"assistant\"):\n",
    "                converted_messages.append(AIMessage(content=message[\"content\"]))\n",
    "        return converted_messages\n",
    "\n",
    "    def generate(context):\n",
    "        payload = context.get_json()\n",
    "        messages = payload.get(\"messages\")\n",
    "        inner_credentials = {\n",
    "            \"url\": service_url,\n",
    "            \"token\": context.get_token()\n",
    "        }\n",
    "\n",
    "        inner_client = APIClient(inner_credentials)\n",
    "        model = create_chat_model(inner_client)\n",
    "        tools = create_tools(inner_client, context)\n",
    "        agent = create_agent(model, tools, messages)\n",
    "        \n",
    "        generated_response = agent.invoke(\n",
    "            { \"messages\": convert_messages(messages) },\n",
    "            { \"configurable\": { \"thread_id\": \"42\" } }\n",
    "        )\n",
    "\n",
    "        last_message = generated_response[\"messages\"][-1]\n",
    "        generated_response = last_message.content\n",
    "\n",
    "        execute_response = {\n",
    "            \"headers\": {\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            },\n",
    "            \"body\": {\n",
    "                \"choices\": [{\n",
    "                    \"index\": 0,\n",
    "                    \"message\": {\n",
    "                       \"role\": \"assistant\",\n",
    "                       \"content\": generated_response\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return execute_response\n",
    "\n",
    "    def generate_stream(context):\n",
    "        print(\"Generate stream\", flush=True)\n",
    "        payload = context.get_json()\n",
    "        headers = context.get_headers()\n",
    "        is_assistant = headers.get(\"X-Ai-Interface\") == \"assistant\"\n",
    "        messages = payload.get(\"messages\")\n",
    "        inner_credentials = {\n",
    "            \"url\": service_url,\n",
    "            \"token\": context.get_token()\n",
    "        }\n",
    "        inner_client = APIClient(inner_credentials)\n",
    "        model = create_chat_model(inner_client)\n",
    "        tools = create_tools(inner_client, context)\n",
    "        agent = create_agent(model, tools, messages)\n",
    "\n",
    "        response_stream = agent.stream(\n",
    "            { \"messages\": messages },\n",
    "            { \"configurable\": { \"thread_id\": \"42\" } },\n",
    "            stream_mode=[\"updates\", \"messages\"]\n",
    "        )\n",
    "\n",
    "        for chunk in response_stream:\n",
    "            chunk_type = chunk[0]\n",
    "            finish_reason = \"\"\n",
    "            usage = None\n",
    "            if (chunk_type == \"messages\"):\n",
    "                message_object = chunk[1][0]\n",
    "                if (message_object.type == \"AIMessageChunk\" and message_object.content != \"\"):\n",
    "                    message = {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": message_object.content\n",
    "                    }\n",
    "                else:\n",
    "                    continue\n",
    "            elif (chunk_type == \"updates\"):\n",
    "                update = chunk[1]\n",
    "                if (\"agent\" in update):\n",
    "                    agent = update[\"agent\"]\n",
    "                    agent_result = agent[\"messages\"][0]\n",
    "                    if (agent_result.additional_kwargs):\n",
    "                        kwargs = agent[\"messages\"][0].additional_kwargs\n",
    "                        tool_call = kwargs[\"tool_calls\"][0]\n",
    "                        if (is_assistant):\n",
    "                            message = {\n",
    "                                \"role\": \"assistant\",\n",
    "                                \"step_details\": {\n",
    "                                    \"type\": \"tool_calls\",\n",
    "                                    \"tool_calls\": [\n",
    "                                        {\n",
    "                                            \"id\": tool_call[\"id\"],\n",
    "                                            \"name\": tool_call[\"function\"][\"name\"],\n",
    "                                            \"args\": tool_call[\"function\"][\"arguments\"]\n",
    "                                        }\n",
    "                                    ] \n",
    "                                }\n",
    "                            }\n",
    "                        else:\n",
    "                            message = {\n",
    "                                \"role\": \"assistant\",\n",
    "                                \"tool_calls\": [\n",
    "                                    {\n",
    "                                        \"id\": tool_call[\"id\"],\n",
    "                                        \"type\": \"function\",\n",
    "                                        \"function\": {\n",
    "                                            \"name\": tool_call[\"function\"][\"name\"],\n",
    "                                            \"arguments\": tool_call[\"function\"][\"arguments\"]\n",
    "                                        }\n",
    "                                    }\n",
    "                                ]\n",
    "                            }\n",
    "                    elif (agent_result.response_metadata):\n",
    "                        # Final update\n",
    "                        message = {\n",
    "                            \"role\": \"assistant\",\n",
    "                            \"content\": agent_result.content\n",
    "                        }\n",
    "                        finish_reason = agent_result.response_metadata[\"finish_reason\"]\n",
    "                        if (finish_reason): \n",
    "                            message[\"content\"] = \"\"\n",
    "\n",
    "                        usage = {\n",
    "                            \"completion_tokens\": agent_result.usage_metadata[\"output_tokens\"],\n",
    "                            \"prompt_tokens\": agent_result.usage_metadata[\"input_tokens\"],\n",
    "                            \"total_tokens\": agent_result.usage_metadata[\"total_tokens\"]\n",
    "                        }\n",
    "                elif (\"tools\" in update):\n",
    "                    tools = update[\"tools\"]\n",
    "                    tool_result = tools[\"messages\"][0]\n",
    "                    if (is_assistant):\n",
    "                        message = {\n",
    "                            \"role\": \"assistant\",\n",
    "                            \"step_details\": {\n",
    "                                \"type\": \"tool_response\",\n",
    "                                \"id\": tool_result.id,\n",
    "                                \"tool_call_id\": tool_result.tool_call_id,\n",
    "                                \"name\": tool_result.name,\n",
    "                                \"content\": tool_result.content\n",
    "                            }\n",
    "                        }\n",
    "                    else:\n",
    "                        message = {\n",
    "                            \"role\": \"tool\",\n",
    "                            \"id\": tool_result.id,\n",
    "                            \"tool_call_id\": tool_result.tool_call_id,\n",
    "                            \"name\": tool_result.name,\n",
    "                            \"content\": tool_result.content\n",
    "                        }\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            chunk_response = {\n",
    "                \"choices\": [{\n",
    "                    \"index\": 0,\n",
    "                    \"delta\": message\n",
    "                }]\n",
    "            }\n",
    "            if (finish_reason):\n",
    "                chunk_response[\"choices\"][0][\"finish_reason\"] = finish_reason\n",
    "            if (usage):\n",
    "                chunk_response[\"usage\"] = usage\n",
    "            yield chunk_response\n",
    "\n",
    "    return generate, generate_stream\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Test locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AI Service function locally\n",
    "from ibm_watsonx_ai.deployments import RuntimeContext\n",
    "\n",
    "context = RuntimeContext(api_client=client)\n",
    "\n",
    "streaming = False\n",
    "findex = 1 if streaming else 0\n",
    "local_function = gen_ai_service(context, vector_index_id=vector_index_id, space_id=space_id)[findex]\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_question = \"Change this question to test your function\"\n",
    "\n",
    "messages.append({ \"role\" : \"user\", \"content\": local_question })\n",
    "\n",
    "context = RuntimeContext(api_client=client, request_payload_json={\"messages\": messages})\n",
    "\n",
    "response = local_function(context)\n",
    "\n",
    "result = ''\n",
    "\n",
    "if (streaming):\n",
    "    for chunk in response:\n",
    "        print(chunk, end=\"\\n\\n\", flush=True)\n",
    "else:\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Store and deploy the AI Service\n",
    "Before you can deploy the AI Service, you must store the AI service in your watsonx.ai repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up software specification for the AI service\n",
    "software_spec_id_in_project = \"45f12dfe-aa78-5b8d-9f38-0ee223c47309\"\n",
    "software_spec_id = \"\"\n",
    "\n",
    "try:\n",
    "    software_spec_id = client.software_specifications.get_id_by_name(\"runtime-24.1-py3.11\")\n",
    "except:\n",
    "    software_spec_id = client.spaces.promote(software_spec_id_in_project, source_project_id, space_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the request and response schemas for the AI service\n",
    "request_schema = {\n",
    "    \"application/json\": {\n",
    "        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"messages\": {\n",
    "                \"title\": \"The messages for this chat session.\",\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"role\": {\n",
    "                            \"title\": \"The role of the message author.\",\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": [\"user\",\"assistant\"]\n",
    "                        },\n",
    "                        \"content\": {\n",
    "                            \"title\": \"The contents of the message.\",\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"role\",\"content\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"messages\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "response_schema = {\n",
    "    \"application/json\": {\n",
    "        \"oneOf\": [{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"type\":\"object\",\"description\":\"AI Service response for /ai_service_stream\",\"properties\":{\"choices\":{\"description\":\"A list of chat completion choices.\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"index\":{\"type\":\"integer\",\"title\":\"The index of this result.\"},\"delta\":{\"description\":\"A message result.\",\"type\":\"object\",\"properties\":{\"content\":{\"description\":\"The contents of the message.\",\"type\":\"string\"},\"role\":{\"description\":\"The role of the author of this message.\",\"type\":\"string\"}},\"required\":[\"role\"]}}}}},\"required\":[\"choices\"]},{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"type\":\"object\",\"description\":\"AI Service response for /ai_service\",\"properties\":{\"choices\":{\"description\":\"A list of chat completion choices\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"index\":{\"type\":\"integer\",\"description\":\"The index of this result.\"},\"message\":{\"description\":\"A message result.\",\"type\":\"object\",\"properties\":{\"role\":{\"description\":\"The role of the author of this message.\",\"type\":\"string\"},\"content\":{\"title\":\"Message content.\",\"type\":\"string\"}},\"required\":[\"role\"]}}}}},\"required\":[\"choices\"]}]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the AI service in the repository\n",
    "ai_service_metadata = {\n",
    "    client.repository.AIServiceMetaNames.NAME: \"AltTabWell\",\n",
    "    client.repository.AIServiceMetaNames.DESCRIPTION: \"corporate wellness \",\n",
    "    client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: software_spec_id,\n",
    "    client.repository.AIServiceMetaNames.CUSTOM: {},\n",
    "    client.repository.AIServiceMetaNames.REQUEST_DOCUMENTATION: request_schema,\n",
    "    client.repository.AIServiceMetaNames.RESPONSE_DOCUMENTATION: response_schema,\n",
    "    client.repository.AIServiceMetaNames.TAGS: [\"wx-agent\"]\n",
    "}\n",
    "\n",
    "ai_service_details = client.repository.store_ai_service(meta_props=ai_service_metadata, ai_service=gen_ai_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the AI Service ID\n",
    "\n",
    "ai_service_id = client.repository.get_ai_service_id(ai_service_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the stored AI Service\n",
    "deployment_custom = {\n",
    "    \"avatar_icon\": \"WatsonHealth3DCurveAutoColon\",\n",
    "    \"avatar_color\": \"supportInfo\",\n",
    "    \"placeholder_image\": \"placeholder5.png\",\n",
    "    \"sample_questions\": [\"generate fitness plan for upcoming leave\",\"What are the most popular wellness interests across the whole company?\"]\n",
    "}\n",
    "deployment_metadata = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: \"AltTabWell\",\n",
    "    client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
    "    client.deployments.ConfigurationMetaNames.CUSTOM: deployment_custom,\n",
    "    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"Alt+Tab+Wellness \",\n",
    "    client.repository.AIServiceMetaNames.TAGS: [\"wx-agent\"]\n",
    "}\n",
    "\n",
    "function_deployment_details = client.deployments.create(ai_service_id, meta_props=deployment_metadata, space_id=space_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test AI Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ID of the AI Service deployment just created\n",
    "\n",
    "deployment_id = client.deployments.get_id(function_deployment_details)\n",
    "print(deployment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "remote_question = \"Change this question to test your function\"\n",
    "messages.append({ \"role\" : \"user\", \"content\": remote_question })\n",
    "payload = { \"messages\": messages }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.deployments.run_ai_service(deployment_id, payload)\n",
    "if \"error\" in result:\n",
    "    print(result[\"error\"])\n",
    "else:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "You successfully deployed and tested the AI Service! You can now view\n",
    "your deployment and test it as a REST API endpoint.\n",
    "\n",
    "<a id=\"copyrights\"></a>\n",
    "### Copyrights\n",
    "\n",
    "Licensed Materials - Copyright © 2024 IBM. This notebook and its source code are released under the terms of the ILAN License.\n",
    "Use, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n",
    "\n",
    "**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n",
    "\n",
    "By downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
